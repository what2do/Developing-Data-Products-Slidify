ylim=c(30, 70))
}
par(op)
#randomForest
op = par(mfrow=c(2, 3))
imp = importance(modFitRF$finalModel)
impvar = rownames(imp)[order(imp[, 1], decreasing=TRUE)]
for (i in seq_along(impvar)) {
partialPlot(modFitRF$finalModel, training, impvar[i], xlab=impvar[i],
main=paste("Partial Dependence on", impvar[i]),
ylim=c(30, 70))
}
par(op)
partialPlot(modFitRF$finalModel, training)
partialPlot(modFitRF$finalModel, training, impvar[i])
partialPlot(modFitRF$finalModel, training, impvar[1])
partialPlot(modFitRF$finalModel, training, impvar[2])
op = par(mfrow=c(2, 3))
imp = importance(modFitRF$finalModel)
impvar = rownames(imp)[order(imp[, 1], decreasing=TRUE)]
for (i in seq_along(impvar)) {
partialPlot(modFitRF$finalModel, training, impvar[i],
main=paste("Partial Dependence on", impvar[i]),
ylim=c(30, 70))
}
par(op)
rownames(training)
names(training)
partialPlot(modFitRF$finalModel, training, Mileage)
partialPlot(modFitRF$finalModel, training, Pontiac)
i.var
length(modFitGBM$finalModel)
op = par(mfrow=c(2, 3))
for (i in 1:(length(training)-1)) {
plot(modFitGBM$finalModel, i.var = i) #only works for gbm,i.var=variable number(i.var:1 = mileage)
}
par(op)
names(training)[2]
names(training)[3]
i=2
partialPlot(modFitRF$finalModel, training, names(training)[i])
#randomForest
op = par(mfrow=c(2, 3))
for (i in 2:length(training)) {
partialPlot(modFitRF$finalModel, training, names(training)[i])
plot(modFitGBM$finalModel, i.var = i) #only works for gbm,i.var=variable number(i.var:1 = mileage)
}
par(op)
#randomForest
op = par(mfrow=c(2, 3))
for (i in 2:length(training)) {
partialPlot(modFitRF$finalModel, training, names(training)[i],main=paste("Partial Dependence on", names(training)[i]),)
plot(modFitGBM$finalModel, i.var = i) #only works for gbm,i.var=variable number(i.var:1 = mileage)
}
par(op)
names(training)[1]
names(training)[18]
#randomForest
op = par(mfrow=c(2, 3))
for (i in 2:length(training)) {
partialPlot(modFitRF$finalModel, training, names(training)[i],main=paste("Partial Dependence on", names(training)[i]),)
}
par(op)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# Predictive model using the 80% PCA predictors
modFitPCANet = train(diagnosis~. , data=training , method="glm", preProcess = "pca", trControl = trainControl(preProcOptions = list(thresh = 0.8)))
predictPCANet = predict(modFitPCANet, testing)
Matrix_PCANet <- confusionMatrix(predictPCANet, testing$diagnosis)
print(Matrix_PCANet)
list(thresh = 0.8)
modFitPCANet = train(diagnosis~. , data=training , method="glm", preProcess = "pca", trControl = trainControl(preProcOptions = list(thresh = 0.1)))
modFitPCANet = train(diagnosis~. , data=training , method="glm", preProcess = "pca", trControl = trainControl(preProcOptions = list(thresh = 0.99)))
warnings()
#####classifcation example#####
data(iris)
set.seed(1234) #there are randomness in createPartiaion, rf and gbm, this helps make our answers consistent
inTrain = createDataPartition(y=iris$Species,p=0.7,list=F)
training = iris[inTrain,]
testing = iris[-inTrain,]
library(caret)
library(ggplot2)
#####classifcation example#####
data(iris)
set.seed(1234) #there are randomness in createPartiaion, rf and gbm, this helps make our answers consistent
inTrain = createDataPartition(y=iris$Species,p=0.7,list=F)
training = iris[inTrain,]
testing = iris[-inTrain,]
trainingPCA=preProcess(training,method=c("pca","scale","center"),thresh=0.9)
View(training)
View(training)
trainingPCA=preProcess(training[,1:4],method=c("pca","scale","center"),thresh=0.9)
plot(trainingPCA)
plot(trainingPCA$rotation)
testingPCA=predict(trainingPCA,testing)
testingPCA=predict(trainingPCA,testing[,1:4])
View(testingPCA)
trainingPCA=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
testingPCA=predict(trainingPCA,testing[,1:4])
trainingPCA$Species=training$Species
View(training)
View(testingPCA)
trainingPCA=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
testingPCA=predict(trainingPCA,testing[,1:4])
trainingPCA$Species=training$Species
trainingPCA=trainingPCA$rotation
View(trainingPCA)
View(training)
View(trainingPCA)
PCA=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
trainingPCA=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
trainingPCA=trainingPCA$x
View(testingPCA)
#Step 1: Reduce number of dimensions to 2 (set it via pcaComp) and apply it to test data
trainingPCA=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
testingPCA=predict(trainingPCA,testing[,1:4])
#Step 2: obtain the PCA data frame
trainingPCA=trainingPCA$x
testingPCA=trainingPCA$x
trainingPCA$Species=training$Species
testingPCA=testingPCA$x
#Step 1: Reduce number of dimensions to 2 (set it via pcaComp) and apply it to test data
trainingPCA=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
testingPCA=predict(trainingPCA,testing[,1:4])
#Step 2: obtain the PCA data frame
trainingPCA=trainingPCA$x
testingPCA=testingPCA$x
#Step 1: Reduce number of dimensions to 2 (set it via pcaComp) and apply it to test data
trainingPCA=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
testingPCA=predict(trainingPCA,testing[,1:4])
trainingPCA=predict(trainingPCA,trainingPCA[,1:4])
trainingPCA=predict(trainingPCA,trainingPCA)
trainingPCA=predict(trainingPCA,training[,1:4])
View(trainingPCA)
trainingPCA=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
x=trainingPCA$x
PCAMod=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
testingPCA=predict(PCAMod,testing[,1:4])
trainingPCA=predict(PCAMod,training[,1:4])
trainingPCA$Species=training$Species
View(trainingPCA)
modFitLDA = train(Species~.,data=trainingPCA,method="lda") #linear discriminant analysis
pred=predict(modFitLDA,testingPCA)
View(testing)
confusionMatrix(pred, testing$Species)
modFitLDA = train(Species~.,data=training,method="rrlda") #linear discriminant analysis
modFitLDA = train(Species~.,data=training,method="rrlda") #linear discriminant analysis
pred=predict(modFitLDA,testing)
confusionMatrix(pred, testing$Species)
modFitLDA = train(Species~.,data=training,method="lda") #linear discriminant analysis
pred=predict(modFitLDA,testing)
confusionMatrix(pred, testing$Species)
data(iris)
set.seed(1234) #there are randomness in createPartiaion, rf and gbm, this helps make our answers consistent
inTrain = createDataPartition(y=iris$Species,p=0.7,list=F)
training = iris[inTrain,]
testing = iris[-inTrain,]
#Step 1: Reduce number of dimensions to 2 (set it via pcaComp) and apply it to test data
PCAMod=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
testingPCA=predict(PCAMod,testing[,1:4])
trainingPCA=predict(PCAMod,training[,1:4])
trainingPCA$Species=training$Species #remember to add back species (dependent variable)
modFitLDA = train(Species~.,data=trainingPCA,method="logreg") #linear discriminant analysis
modFitLDA = train(Species~.,data=trainingPCA,method="glm",family="binomial") #linear discriminant analysis
warnings()
modFitLDA = train(Species~.,data=trainingPCA,method="glm") #linear discriminant analysis
warnings()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# Predictive model using the 80% PCA predictors
modFitPCANet = train(diagnosis~. , data=training , method="glm", preProcess = "pca", trControl = trainControl(preProcOptions = list(thresh = 0.8)))
predictPCANet = predict(modFitPCANet, testing)
Matrix_PCANet <- confusionMatrix(predictPCANet, testing$diagnosis)
print(Matrix_PCANet)
#Step 1: Reduce number of dimensions to 2 (set it via pcaComp) and apply it to test data
PCAMod=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
testingPCA=predict(PCAMod,testing[,1:4])
trainingPCA=predict(PCAMod,training[,1:4])
trainingPCA$Species=training$Species #remember to add back species (dependent variable)
#Step 2: train using PCA adjusted data
modFitRF= train(Species~.,data=trainingPCA,method="rf")
pred=predict(modFitRF,testingPCA)
confusionMatrix(pred, testing$Species)
#####classifcation example#####
data(iris)
set.seed(1234) #there are randomness in createPartiaion, rf and gbm, this helps make our answers consistent
inTrain = createDataPartition(y=iris$Species,p=0.7,list=F)
training = iris[inTrain,]
testing = iris[-inTrain,]
#Step 1: Reduce number of dimensions to 2 (set it via pcaComp) and apply it to test data
PCAMod=preProcess(training[,1:4],method=c("pca","scale","center"),pcaComp=2)
testingPCA=predict(PCAMod,testing[,1:4])
trainingPCA=predict(PCAMod,training[,1:4])
trainingPCA$Species=training$Species #remember to add back species (dependent variable)
#Step 2: train using PCA adjusted data
modFitRF= train(Species~.,data=trainingPCA,method="rf")
pred=predict(modFitRF,testingPCA)
confusionMatrix(pred, testing$Species)
library(ggplot2)
library(caret)
data(cars)
#####regression example#####
#optional: set multicore
library(cluster)
library(parallel)
library(doSNOW)
coreNumber=max(detectCores(),1)
cluster=makeCluster(coreNumber, type = "SOCK",outfile="")
registerDoSNOW(cluster)
#take a look at data...there seems to be a lot of 1s and 0s?
summary(cars)
# some of the columns are categorical (factors)
factorCols=c("Cruise","Sound","Leather","Buick","Cadillac","Chevy","Pontiac","Saab","Saturn",
"convertible","coupe","hatchback","sedan","wagon")
cars[factorCols] = data.frame(lapply(cars[factorCols], function(x) factor(x) ))
summary(cars)
# optional: normalize the numeric data (except for what we trying to predict, price)
# may improve model accuracy but makes it harder to interpret data.
# preObj = preProcess(cars[,c("Doors","Mileage","Cylinder")], method=c("scale","center"))
# cars[,c("Doors","Mileage","Cylinder")] = predict(preObj, cars[,c("Doors","Mileage","Cylinder")])
# summary(cars)
#prepare the data, 70% train, 30% test
set.seed(1234) #there are randomness in createPartiaion, rf and gbm, this helps make our answers consistent
inTrain = createDataPartition(y=cars$Price,p=0.7,list=F)
training = cars[inTrain,]
testing = cars[-inTrain,]
#tune the model (advanced stuff, needs to be customized for different models)
#here we only tune gbm
gbmGrid =  expand.grid(interaction.depth = c(1, 5, 9), n.trees = (1:10)*50, shrinkage = 0.1)
fitControl = trainControl(method = "cv", number = 10)
ptm = proc.time()
modFitRR = train(Price~.,data=training,method="ridge") #ridge regression
proc.time() - ptm
proc.time()
install.packages("manipulate")
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
install.packages("rCharts")
library(rCharts)
library(devtools)
install_github("rCharts", "ramnathv")
library(rCharts)
load(airquality)
import(airquality)
library(airquality)
load(airquality)
data=airquality
dTable(airquality, sPaginationType = "full_numbers")
library(shiny)
runExample("01_hello")
runExample("01_hello")
runApp("App-1")
setwd("~/Documents/coursera developing data product/shiny")
setwd("~/Documents/coursera/developing data product/shiny")
runApp("App-1")
runApp("App-1")
runApp("App-2")
runApp("App-2")
install.packages(c("maps", "mapproj"))
runApp("census-app")
runApp("stockVis")
runApp("stockVis")
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='thiakx', token='D9C9AB65AD8721357F40681920FF143D', secret='Uj1xGh5xjKlSGo0C1zvFRQls79jDVB2Mmx57kuvn')
library(shinyapps)
shinyapps::deployApp('stockVis')
shinyapps::deployApp('simple')
shinyapps::deployApp('census')
#from shiny tutorial: http://shiny.rstudio.com/tutorial/
#make sure the libs are isntalled: "shiny","maps", "mapproj", "shinyapps"
setwd("~/Documents/coursera/developing data product/shiny")
library(shiny)
shinyapps::deployApp('stockVis')
runExample("01_hello") # a histogram
runGitHub( "stockVisDemo", "thiakx")
runGitHub( "stockVisDemo", "thiakx")
#setwd("yourpath")
library(shiny)
#simple app
runApp("simple")
#app with widgets
runApp("census")
#stock market app
runApp("stockVis")
install.packages("quantmod")
#stock market app
runApp("stockVis")
runExample("01_hello") # a histogram
runExample("02_text") # tables and data frames
runApp("simple")
#setwd("yourpath")
library(shiny)
#simple app
runApp("riskcalculator")
runExample("07_widgets") # help text and submit buttons
runExample("08_html") # Shiny app built from HTML
runExample("04_mpg") # global variables
runExample("06_tabsets") # tabbed panels
runExample("02_text") # tables and data frames
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
runExample("03_reactivity") # a reactive expression
#simple app
runApp("riskcalculator")
runExample("07_widgets") # help text and submit buttons
runExample("06_tabsets") # tabbed panels
runExample("01_hello") # a histogram
runExample("02_text") # tables and data frames
runApp("riskcalculator")
runApp("riskcalculator")
runExample("07_widgets") # help text and submit buttons
#simple app
runApp("riskcalculator")
runExample("07_widgets") # help text and submit buttons
runApp("riskcalculator")
runApp("riskcalculator", display.mode = "showcase")
#setwd("yourpath")
library(shiny)
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
runApp("stockVis")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#setwd("yourpath")
library(shiny)
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
runApp("riskcalculator")
install.packages("rcharts")
install.packages("rCharts")
install_github("ramnathv/rCharts@dev")
library(devtools)
install_github("ramnathv/rCharts@dev")
runApp("riskcalculator")
install.packages('base64enc')
devtools::install_github('ramnathv/rCharts')
runApp("riskcalculator")
runApp("riskcalculator")
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#setwd("yourpath")
library(shiny)
#simple app
runApp("riskcalculator")
runExample("02_text") # tables and data frames
#from shiny tutorial: http://shiny.rstudio.com/tutorial/
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
#simple app
runApp("riskcalculator")
library(slidify)
##to initialize the deck
setwd("C:\Users\Charles\Documents\R\thiakx.github.io-master\shiny\what2do\")
author("what2do")
slidify("index.Rmd")
runDeck() #note: may need to install.packages('XML') #note2:
install.packages("xml")
install.packages("XML")
##to initialize the deck
setwd("C:\Users\Charles\Documents\R\thiakx.github.io-master\shiny\what2do\")
author("what2do")
slidify("index.Rmd")
runDeck() #note: may need to install.packages('XML') #note2:
